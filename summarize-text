#!/usr/bin/env bash

set -e -o pipefail
shopt -s dotglob

# Get the base name of the script for help text
cmd_base=$(basename "$0")

# Simple info function for logging
info() {
   echo "ðŸ”·ï¸ðŸ”·ï¸ðŸ”·ï¸ $* ðŸ”·ï¸ðŸ”·ï¸ðŸ”·ï¸" >&2
}

display_help_text_and_die() {
   cat - <<EOM
USAGE:
   some_command | $cmd_base [OPTION]
   - or -
   $cmd_base [OPTION] FILE
   - or -
   $cmd_base [OPTION] URL
WTF:
   Summarize the text from STDIN
OPTIONS:
   -l | --ollama:  Use the Ollama API with mistral (runs locally, 
                   requires ollama launchd service to be running)
   -o | --openai:  Use the OpenAI API (default)
   -c | --claude:  Use the Claude API 
EOM
   exit 1
}

if [[ "$1" == "-h" ]] || [[ "$1" == "--help" ]]; then
   display_help_text_and_die
fi

# check for bash v3.2+
if [ "${BASH_VERSINFO[0]}" -lt 3 ] || ([ "${BASH_VERSINFO[0]}" -eq 3 ] && [ "${BASH_VERSINFO[1]}" -lt 2 ]); then
   echo "This script requires bash 3.2 or higher."
   exit 1
fi

ollama_summarize() {
   info "Summarizing text with ollama"
   # brew services start ollama # just in case it's not already running
   if ! command -v ollama >/dev/null 2>&1; then
      echo "â€¼ï¸ Ollama not found. Is it installed?" >&2
      exit 1
   fi
   ollama run "$ollama_model" "$prompt"
}

openai_summarize() {
   info "Summarizing text with OpenAI"
   source ~/.ssh/.openai-api-key.sh

   curl https://api.openai.com/v1/chat/completions \
      -s \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d "$(jq -n --arg prompt "$prompt" \
         '{
            model: "gpt-4o",
            messages: [
              {
                role: "user",
                content: $prompt
               }
            ]
      }')" | jq -r '.choices[0].message.content'
}

claude_summarize() {
   info "Summarizing text with Claude"
   command -v claude >/dev/null 2>&1 || exit 1
   source ~/.ssh/.claude-api-key.sh
   claude "$prompt"
}

active_function=openai_summarize
ollama_model=mistral
source=STDIN
source_identifier=""

while [ $# -gt 0 ]; do
   case $1 in
   -l* | --ollama*)
      active_function="ollama"
      if [ -n ${1#*=} ]; then
         ollama_model="${1#*=}"
      fi
      ;;
   -o | --openai)
      active_function=openai_summarize
      ;;
   -c | --claude)
      active_function=claude_summarize
      ;;
   http://* | https://*)
      source=URL
      source_identifier="$1"
      ;;
   *)
      source=FILE
      source_identifier="$1"
      ;;
   esac
   shift
done

construct_prompt() {
   prompt="summarize the following text:"
   prompt+=$'\n'
   while ifs= read -r line; do
      prompt+=$'\n'"$line"
   done
}

case "$source" in
STDIN)
   construct_prompt
   $active_function
   ;;
URL)
   construct_prompt < <(curl -s "$source_identifier" | html2text)
   $active_function
   ;;
FILE)
   construct_prompt <"$source_identifier"
   $active_function
   ;;
*)
   echo "Unknown source type: $source"
   exit 1
   ;;
esac
