#!/usr/bin/env bash

set -e -o pipefail
shopt -s dotglob

# Get the base name of the script for help text
cmd_base=$(basename "$0")
pre_prompt="Briefly summarize the following text in a few bullets, preserving the original meaning. At the end, call out themes that seem pertinent or interesting."

prompt+=$'\n\n--------\n'
# Simple info function for logging
info() {
   echo "🔷️🔷️🔷️ $* 🔷️🔷️🔷️" >&2
}

display_help_text_and_die() {
   cat - <<EOM
USAGE:
   some_command | $cmd_base [OPTION]
   - or -
   $cmd_base [OPTION] FILE
   - or -
   $cmd_base [OPTION] URL
WTF:
   Summarize the text from STDIN
OPTIONS:
   -l | --ollama:  Use the Ollama API with mistral (runs locally, 
                   requires ollama launchd service to be running)
      --ollama=model_name:  Use the Ollama API with specified model
   -o | --openai:  Use the OpenAI API (default)
      --openai=model_name:  Use the OpenAI API with specified model
   -c | --claude:  Use the Claude API 
   -p | --preprompt="text":  Use custom pre-prompt text
DEFAULTS:
   --openai=gpt-4o:
      Use the OpenAI API with gpt-4o model
   Pre-prompt:
      "$pre_prompt"

EOM
   exit 1
}

if [[ "$1" == "-h" ]] || [[ "$1" == "--help" ]]; then
   display_help_text_and_die
fi

# check for bash v3.2+
if [ "${BASH_VERSINFO[0]}" -lt 3 ] || ([ "${BASH_VERSINFO[0]}" -eq 3 ] && [ "${BASH_VERSINFO[1]}" -lt 2 ]); then
   echo "This script requires bash 3.2 or higher."
   exit 1
fi

ollama_summarize() {
   info "Summarizing text with ollama using model: $ollama_model"
   # brew services start ollama # just in case it's not already running
   if ! command -v ollama >/dev/null 2>&1; then
      echo "‼️ Ollama not found. Is it installed?" >&2
      exit 1
   fi

   # Check if the model is available
   if ! ollama list | grep -q "^$ollama_model:"; then
      echo "⚠️ Model '$ollama_model' not found locally." >&2
      echo "Available models:" >&2
      ollama list >&2
      echo >&2
      read -p "Download '$ollama_model'? (y/N): " -n 1 -r >&2
      echo >&2
      if [[ "${REPLY,,}" == y ]]; then
         info "Downloading model: $ollama_model"
         ollama pull "$ollama_model" || {
            echo "❌ Failed to download model '$ollama_model'." >&2
            exit 1
         }
      else
         echo "❌ Cannot proceed without the model. Exiting." >&2
         exit 1
      fi
   fi

   ollama run "$ollama_model" "$prompt"
}

openai_summarize() {
   info "Summarizing text with OpenAI using model: $openai_model"
   source ~/.ssh/.openai-api-key.sh

   curl https://api.openai.com/v1/chat/completions \
      -s \
      -H "Authorization: Bearer $OPENAI_API_KEY" \
      -H "Content-Type: application/json" \
      -d "$(jq -n --arg prompt "$prompt" --arg model "$openai_model" \
         '{
            model: $model,
            messages: [
              {
                role: "user",
                content: $prompt
               }
            ]
      }')" | jq -r '.choices[0].message.content'
}

claude_summarize() {
   info "Summarizing text with Claude"
   command -v claude >/dev/null 2>&1 || exit 1
   source ~/.ssh/.claude-api-key.sh
   claude "$prompt"
}

active_function=openai_summarize
ollama_model=mistral
openai_model=gpt-4o
source=STDIN
source_identifier=""

while [ $# -gt 0 ]; do
   case $1 in
   -l* | --ollama*)
      active_function=ollama_summarize
      if [[ $1 =~ =(.*)$ ]]; then
         ollama_model="${BASH_REMATCH[1]}"
      fi
      ;;
   -o* | --openai*)
      active_function=openai_summarize
      if [[ $1 =~ =(.*)$ ]]; then
         openai_model="${BASH_REMATCH[1]}"
      fi
      ;;
   -c | --claude)
      active_function=claude_summarize
      ;;
   -p* | --preprompt*)
      if [[ $1 =~ =(.*)$ ]]; then
         pre_prompt="${BASH_REMATCH[1]}"
      else
         shift
         pre_prompt="$1"
      fi
      ;;
   http://* | https://*)
      source=URL
      source_identifier="$1"

      command -v curl >/dev/null 2>&1 && command -v html2text >/dev/null 2>&1 || {
         echo "‼️ curl and html2text are required to fetch and convert HTML content." >&2
         exit 1
      }

      ;;
   *)
      source=FILE
      source_identifier="$1"
      ;;
   esac
   shift
done

construct_prompt() {
   prompt="$pre_prompt\n\n--------\n"
   while IFS= read -r line; do
      prompt+=$'\n'"$line"
   done
}

case "$source" in
STDIN)
   construct_prompt
   $active_function
   ;;
URL)
   construct_prompt < <(curl -s "$source_identifier" | html2text)
   $active_function
   ;;
FILE)
   construct_prompt <"$source_identifier"
   $active_function
   ;;
*)
   echo "Unknown source type: $source"
   exit 1
   ;;
esac
